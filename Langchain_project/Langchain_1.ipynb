{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94adb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'sk-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "001a9dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kris\\AppData\\Local\\Temp\\ipykernel_32780\\2259831809.py:8: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.6)\n",
      "C:\\Users\\Kris\\AppData\\Local\\Temp\\ipykernel_32780\\2259831809.py:11: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  name = llm(\"I want to open a restaurant for Italian food. Suggest some fancy names for this.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. \"Bella Cucina\" \n",
      "2. \"La Dolce Vita\" \n",
      "3. \"Ciao Bella\" \n",
      "4. \"Mama Mia's Trattoria\" \n",
      "5. \"Grazie Ristorante\" \n",
      "6. \"La Famiglia\" \n",
      "7. \"La Piazza\" \n",
      "8. \"Ristorante Amore\" \n",
      "9. \"Bella Notte\" \n",
      "10. \"Vino e Cucina\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "# Create a text-generation pipeline with Hugging Face\n",
    "# generator = pipeline(\"text-generation\", model=\"tiiuae/falcon-rw-1b\")\n",
    "\n",
    "# Initialize LangChain's HuggingFacePipeline with that pipeline\n",
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "# Generate some restaurant names\n",
    "name = llm(\"I want to open a restaurant for Italian food. Suggest some fancy names for this.\")\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b85cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Italian food. Suggest a fancy name for it'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_temp = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for it\"\n",
    ")\n",
    "prompt_temp.format(cuisine=\"Italian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6873eabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kris\\AppData\\Local\\Temp\\ipykernel_32780\\21979908.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt = prompt_temp)\n",
      "C:\\Users\\Kris\\AppData\\Local\\Temp\\ipykernel_32780\\21979908.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"American\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"Stateside Eats\" '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#its a method to link multiple steps like an LLM workflow\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt = prompt_temp)\n",
    "chain.run(\"American\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df84cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential Chain\n",
    "llm = OpenAI(temperature=0.6)\n",
    "prompt_temp = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for it\"\n",
    ")\n",
    "prompt_temp.format(cuisine=\"Italian\")\n",
    "chain = LLMChain(llm=llm, prompt = prompt_temp)\n",
    "\n",
    "prompt_temp_items = PromptTemplate(\n",
    "    input_variables= ['restaurant name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comma separated.\"\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt = prompt_temp_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "178b92c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Tandoori chicken\n",
      "2. Vegetable samosas\n",
      "3. Butter chicken\n",
      "4. Lamb biryani\n",
      "5. Palak paneer\n",
      "6. Naan bread\n",
      "7. Mango lassi\n",
      "8. Chicken tikka masala\n",
      "9. Aloo gobi\n",
      "10. Chana masala\n",
      "11. Dal makhani\n",
      "12. Vegetable korma\n",
      "13. Malai kofta\n",
      "14. Chicken curry\n",
      "15. Gulab jamun dessert.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain2 = SimpleSequentialChain(chains = [chain , chain1])\n",
    "response = chain2.run(\"Indian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3619ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "prompt_temp = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for it\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt = prompt_temp, output_key = \"restaurant_name\")\n",
    "\n",
    "llm = OpenAI(temperature=0.6)\n",
    "prompt_temp_items = PromptTemplate(\n",
    "    input_variables= ['restaurant name'],\n",
    "    template = \"Suggest some menu items for {restaurant_name}. Return it as a comma separated.\"\n",
    ")\n",
    "chain1 = LLMChain(llm=llm, prompt = prompt_temp_items, output_key = \"menu_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefb3972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\n\"Sultana\\'s Palace\"',\n",
       " 'menu_items': '\\n\\n1. Meze platter (hummus, baba ghanoush, tabbouleh, stuffed grape leaves)\\n2. Lamb kebab with rice pilaf\\n3. Chicken shawarma wrap\\n4. Falafel platter\\n5. Beef kofta with tzatziki sauce\\n6. Spinach and feta spanakopita\\n7. Grilled halloumi cheese salad\\n8. Lentil soup\\n9. Baklava for dessert\\n10. Turkish coffee or mint tea for drinks'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain3 = SequentialChain(\n",
    "    chains = [chain, chain1],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables = ['restaurant_name', 'menu_items']\n",
    ")\n",
    "chain3({'cuisine':'Arabic' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f7a1a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use wikipedia to find out information about Elon Musk's birthdate and his current age.\n",
      "Action: wikipedia\n",
      "Action Input: \"Elon Musk\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
      "Summary: Elon Reeve Musk ( EE-lon; born June 28, 1971) is a businessman. He is known for his leadership of Tesla, SpaceX, X (formerly Twitter), and the Department of Government Efficiency (DOGE). Musk has been considered the wealthiest person in the world since 2021; as of May 2025, Forbes estimates his net worth to be US$424.7 billion. \n",
      "Born to a wealthy family in Pretoria, South Africa, Musk emigrated in 1989 to Canada. He received bachelor's degrees from the University of Pennsylvania in 1997 before moving to California, United States, to pursue business ventures. In 1995, Musk co-founded the software company Zip2. Following its sale in 1999, he co-founded X.com, an online payment company that later merged to form PayPal, which was acquired by eBay in 2002. That year, Musk also became an American citizen.\n",
      "In 2002, Musk founded the space technology company SpaceX, becoming its CEO and chief engineer; the company has since led innovations in reusable rockets and commercial spaceflight. Musk joined the automaker Tesla as an early investor in 2004 and became its CEO and product architect in 2008; it has since become a leader in electric vehicles. In 2015, he co-founded OpenAI to advance artificial intelligence research but later left; growing discontent with the organization's direction and their leadership in the AI boom in the 2020s led him to establish xAI. In 2022, he acquired the social network Twitter, implementing significant changes and rebranding it as X in 2023. His other businesses include the neurotechnology company Neuralink, which he co-founded in 2016, and the tunneling company the Boring Company, which he founded in 2017. He was named Time magazine's Person of the Year in 2021.\n",
      "Musk's political activities and views have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation and promoting conspiracy theories, and affirming antisemitic, racist, and transphobic comments. His acquisition of Twitter was controversial due to a subsequent increase in hate speech and the spread of misinformation on the service. Musk was the largest donor in the 2024 U.S. presidential election, and is a supporter of global far-right figures, causes, and political parties. In early 2025, he served as senior advisor to United States president Donald Trump and as the de facto head of DOGE. His role in the second Trump administration attracted public backlash, particularly in response to DOGE.\n",
      "\n",
      "Page: Elon Musk–Donald Trump feud\n",
      "Summary: In June 2025, businessman and former presidential advisor Elon Musk and U.S. president Donald Trump engaged in a brief series of social media spats, primarily across Twitter and Truth Social,\n",
      "following Musk's exit from Trump's administration with his criticisms of the One Big Beautiful Bill Act, a bill intended to be landmark legislation for Trump.\n",
      "Prior to being political allies in 2024, Musk and Trump shared a history of mutual provocation. In 2022, Musk described Trump as an unsuitable president due to his age in response to Trump calling him a \"bullshit artist\", and briefly feuded with Trump.\n",
      "\n",
      "\n",
      "\n",
      "Page: Elon Musk salute controversy\n",
      "Summary: On January 20, 2025, while speaking at a rally celebrating U.S. president Donald Trump's second inauguration, businessman and political figure Elon Musk twice made a salute interpreted by many as a Nazi or a fascist Roman salute.\n",
      "It was widely condemned as an intentional Nazi salute in Germany, where making such gestures is illegal. The Anti-Defamation League said it was not a Nazi salute, but other Jewish organizations disagreed and condemned the salute. American public opinion was divided on partisan lines as to whether it was a fascist salute. Musk dismissed the accusations of Nazi sympathies, deriding them as \"dirty tricks\" and a \"tired\" attack. Neo-Nazi and white supremacist groups celebrated it as a Nazi salute. Multiple European political parties demanded that Musk b\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the calculator to find out Elon Musk's age in 2025.\n",
      "Action: Calculator\n",
      "Action Input: \"2025 - 1971\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 54\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should subtract 54 from 2025 to find out Elon Musk's age in 2025.\n",
      "Action: Calculator\n",
      "Action Input: \"2025 - 54\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 1971\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Elon Musk was born in 1971, so his age in 2025 would be 54. \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk was born in 1971, so his age in 2025 would be 54.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "from langchain.llms import OpenAI \n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True\n",
    ")\n",
    "agent.run(\"When was Elon musk born? What is his age right now in 2025\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b334806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = \"bea2ebb433e18d1c984cfa0b69f59ccd9bc4ee2191018cb2fa2ab6c843188b9b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f39f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer.\n",
      "Action: Search\n",
      "Action Input: \"GDP India 2024\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['Real GDP growth. Annual percent change. 6.2 ; GDP, current prices. Billions of U.S. dollars. 4.19 ; GDP per capita, current prices. U.S. dollars per capita. 2.88.', 'Economy of India ; Negative increase –$44.563 billion (2024) · Negative increase –1.146% of GDP (2024) · Negative increase $663.8 billion (March 2024) · ( Positive ...', \"Additionally, as per IMF projections, India's GDP grow is at 6.2% in 2024-25 and 2025-26. This means India's economic growth next fiscal year ...\", 'While a significant uptick in economic activity in the fourth quarter of financial year 2024-25 pushed GDP growth for the full year to 6.5%, ...', \"India's third-quarter gross domestic product numbers for fiscal year 2024 to 2025—standing at 6.2% year-over-year growth—coupled with the recent ...\", \"GDP in India is estimated to be $3.425 Trillion US dollars at the end of 2024 in Real GDP terms. Looking ahead to 2025, projections suggest India's 2025 GDP ...\", 'India GDP for 2023 was 3.568 trillion US dollars, a 6.38% increase from 2022. · India GDP for 2022 was 3.353 trillion US dollars, a 5.88% increase from 2021.', 'At a Glance ; 2025 Projected Real GDP (% Change) : 6.2 ; 2025 Projected Consumer Prices (% Change): 4.2 ; Country Population: 1,454.607 million ; Date of Membership ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to calculate the GDP from the given data.\n",
      "Action: Calculator\n",
      "Action Input: GDP = 4.19 billion USD, GDP growth rate = 6.2%\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 4.4497800000000005\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The GDP of India in 2024 is estimated to be 4.4497800000000005 trillion USD.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The GDP of India in 2024 is estimated to be 4.4497800000000005 trillion USD.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)\n",
    "\n",
    "agent.run(\"What is the GDP of India in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5024b323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Stateside Elegance\"\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt = prompt_temp)\n",
    "name = chain.run(\"American\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09c1bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Stateside Bistro\"\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain4 = LLMChain(llm=llm, prompt = prompt_temp, memory=memory)\n",
    "name = chain4.run(\"American\")\n",
    "print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5e87d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Spice Palace\" \n"
     ]
    }
   ],
   "source": [
    "name = chain4.run(\"Indian\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416f0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: American\n",
      "AI: \n",
      "\n",
      "\"Stateside Bistro\"\n",
      "Human: Indian\n",
      "AI: \n",
      "\n",
      "\"Spice Palace\" \n"
     ]
    }
   ],
   "source": [
    "print(chain4.memory.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf58caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kris\\AppData\\Local\\Temp\\ipykernel_32780\\1870763344.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  convo = ConversationChain(llm=OpenAI(temperature = 0.7))\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature = 0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75bd5de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first cricket world cup was won by the West Indies in 1975.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68e75478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' India won the cricket world cup in 1983 and again in 2011. The 1983 win was their first and they defeated the West Indies in the final. In 2011, they defeated Sri Lanka in the final.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"When did India win the cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd6711b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the first cricket world cup?\n",
      "AI:  The first cricket world cup was won by the West Indies in 1975.\n",
      "Human: When did India win the cricket world cup?\n",
      "AI:  India won the cricket world cup in 1983 and again in 2011. The 1983 win was their first and they defeated the West Indies in the final. In 2011, they defeated Sri Lanka in the final.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "902b1573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Cricket World Cup was won by the West Indies in 1975. They defeated Australia in the final by 17 runs. The tournament was held in England and was organized by the International Cricket Council. The West Indies team was led by Clive Lloyd and included players like Viv Richards, Gordon Greenidge, and Michael Holding.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm = OpenAI(temperature=0.6),\n",
    "    memory = memory\n",
    ")\n",
    "convo.run(\"Who won the first Cricket World Cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e8faf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  5+5 is equal to 10.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "576327ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I do not have enough context to answer that question. Can you provide more information?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"who was the winning captain?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
